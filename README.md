# ğŸ§  Secure Local Chatbot Architecture â€“ Technical Documentation

> **Purpose**: Provide a fully containerized, JWT-secured, self-hosted chatbot architecture using `llama-cpp`, reverse-proxied via `NGINX` with HTTPS. Built for high-compliance, isolated enterprise environments.

---

## ğŸ“ Project Directory Structure

```
chatbot_enterprise_local/
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ nginx/
â”‚   â”œâ”€â”€ nginx.conf
â”‚   â””â”€â”€ certs/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ auth_service/
â”‚   â”‚   â”œâ”€â”€ main.py
â”‚   â”‚   â”œâ”€â”€ ldap_sim.py
â”‚   â”‚   â”œâ”€â”€ requirements.txt
â”‚   â”œâ”€â”€ chat_service/
â”‚   â”‚   â”œâ”€â”€ main.py
â”‚   â”‚   â”œâ”€â”€ inference.py
â”‚   â”‚   â”œâ”€â”€ requirements.txt
â”‚   â”œâ”€â”€ shared/
â”‚   â”‚   â”œâ”€â”€ jwt_utils.py
â”‚   â”‚   â”œâ”€â”€ rbac.py
â”‚   â”œâ”€â”€ log_service/
â”‚   â”‚   â””â”€â”€ responses_logs/
â”‚   â”‚       â””â”€â”€ chatbot_logs.log
â”œâ”€â”€ models/
â”‚   â””â”€â”€ TinyLLAMA/
â”‚       â””â”€â”€ tinyllama-1.1b-chat-v1.0.Q4_K_S.gguf  âŒ Not included in repo
â”œâ”€â”€ data/
â”‚   â””â”€â”€ users/
â”‚       â””â”€â”€ users.yaml
```

---

## ğŸ” Auth Service

- **Port**: `5000`
- **Responsibilities**:
  - Handles login via `/login`
  - Verifies credentials in YAML (`users.yaml`)
  - Issues JWT token via `jwt_utils.py`

### ğŸ”“ Endpoint

```http
POST /login
```

### âœ… JWT Payload

```json
{
  "username": "analyst1",
  "role": "analyst",
  "exp": 1744474210
}
```

---

## ğŸ¤– Chat Service

- **Port**: `5101`
- **Responsibilities**:
  - Validates JWT via decorators
  - Calls TinyLLAMA via `llama-cpp-python`
  - Logs prompts & responses using `loguru`

### Environment Variables

```
MODEL_PATH=/app/models/TinyLLAMA/tinyllama-1.1b-chat-v1.0.Q4_K_S.gguf
LOG_DIR=/app/log_service/responses_logs
```

---

## ğŸŒ NGINX Reverse Proxy (HTTPS)

- **Port**: `8443`
- **Features**:
  - TLS termination via self-signed or CA cert
  - CORS preflight support
  - Reverse proxies:
    - `/login` âœ `auth_service`
    - `/chat` âœ `chat_service`

---

## ğŸ³ Docker Compose Setup

```yaml
version: '3.8'

services:
  auth_service:
    build: ./app/auth_service
    ports:
      - "5000:5000"
    environment:
      - JWT_SECRET_KEY=your_secret_key
    volumes:
      - ./data/users:/app/data/users
      - ./app/shared:/app/shared
    networks:
      - chatbot_network

  chat_service:
    build: ./app/chat_service
    ports:
      - "5101:5101"
    depends_on:
      - auth_service
    environment:
      - MODEL_PATH=/app/models/TinyLLAMA/tinyllama-1.1b-chat-v1.0.Q4_K_S.gguf
      - LOG_DIR=/app/log_service/responses_logs
    volumes:
      - ./app/shared:/app/shared
      - ./app/chat_service/models/TinyLLAMA:/app/models/TinyLLAMA
      - ./app/log_service/responses_logs:/app/log_service/responses_logs
    networks:
      - chatbot_network

  nginx:
    image: nginx:latest
    ports:
      - "8080:80"
      - "8443:443"
    volumes:
      - ./nginx/nginx.conf:/etc/nginx/nginx.conf:ro
      - ./nginx/certs:/etc/nginx/certs:ro
    depends_on:
      - auth_service
      - chat_service
    networks:
      - chatbot_network

networks:
  chatbot_network:
    driver: bridge
```

---

## ğŸ§ª Curl Testing

### Login Request

```bash
curl -k https://localhost:8443/login \
  -H "Content-Type: application/json" \
  -d '{"username": "analyst1", "password": "pass123"}'
```

### Chat Request

```bash
curl -k https://localhost:8443/chat \
  -H "Authorization: Bearer <JWT_TOKEN>" \
  -H "Content-Type: application/json" \
  -d '{"prompt": "What are the key banking risks in Egypt?"}'
```

---

## ğŸ” Security Design

- ğŸ”’ JWT + Role-based Access Control (`@requires_auth`, `@requires_role`)
- ğŸ” TLS-encrypted traffic (via `nginx`)
- ğŸ” Explicit CORS control (headers + preflight logic)
- ğŸ” Logs rotated, compressed, and persisted
- ğŸ” Internal Docker network for service isolation

---

## ğŸ¯ Future Roadmap

- [ ] Refresh Token + Logout endpoint
- [ ] RBAC Admin Panel (React)
- [ ] Monitoring via Prometheus + Grafana
- [ ] Model switching via UI
- [ ] GitHub Actions for CI/CD

---

> âœ… Production-grade LLM deployment architecture  
> ğŸ” Designed for regulated environments (banking, fintech, telcos)  
> ğŸ‘¨â€ğŸ’» Built by engineers. Not just a pretty demo.
